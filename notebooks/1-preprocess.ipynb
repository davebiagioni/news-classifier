{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to preprocess the dataset for input into our ML models using spacy for tokenization, lemmatization, and PoS tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from string import printable\n",
    "import spacy\n",
    "import tld\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataframe from the text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions.\n",
    "\n",
    "def get_file_list(datadir, exclude_regex=None):\n",
    "  '''Get a list of the data files.'''\n",
    "  files = []\n",
    "  for dirpath, dirnames, filenames in os.walk(datadir):\n",
    "    if len(filenames) > 0:\n",
    "      files.extend([os.path.join(dirpath, x) for x in filenames])\n",
    "  if exclude_regex:\n",
    "    files = [x for x in files if not re.match(exclude_regex, x)]\n",
    "  return files\n",
    "      \n",
    "def clean_string(string):\n",
    "  '''Simple preprocessing to remove non-printable characters and excess whitespace.'''\n",
    "  string = re.sub('\\s+', ' ', string)\n",
    "  string = ''.join([s for s in string if s in printable])\n",
    "  return string\n",
    "\n",
    "def create_dataframe(files=None):\n",
    "  '''Create a dataframe from a file list, filtering out non-political articles.'''\n",
    "  \n",
    "  df = pd.DataFrame(columns=['text', 'label', 'url'], data=np.chararray((len(files), 3)))\n",
    "  \n",
    "  row = 0\n",
    "  for filename in files:\n",
    "    \n",
    "    # Open file.\n",
    "    with open(filename, 'r') as f:\n",
    "      data = json.load(f)\n",
    "    \n",
    "    # Skip if no taxonomy labels.\n",
    "    if len(data['taxonomy']) == 0:\n",
    "      continue\n",
    "\n",
    "    # Get taxonomy labels and filter on \"politics\", skipping if none exist.\n",
    "    labels = [data['taxonomy'][i]['label'] for i in range(len(data['taxonomy']))]\n",
    "    labels = [x for x in labels if re.match('.*politics', x)]\n",
    "    if len(labels) == 0:\n",
    "      continue\n",
    "\n",
    "    # Populate row, doing basic cleaning of whitespace and non-printable characters\n",
    "    # in the article text.\n",
    "    df.loc[row] = [clean_string(data['text']), data['label'], data['url']]\n",
    "\n",
    "    # Keeping track of the last row we populated.\n",
    "    row += 1\n",
    "\n",
    "  # Drop empty rows at tale of dataframe.\n",
    "  df = df.drop(df.index[row:])\n",
    "  \n",
    "  return df\n",
    "\n",
    "def create_dataframe_mp(files):\n",
    "  return create_dataframe(files=files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conservative/liberal articles: 38162\n"
     ]
    }
   ],
   "source": [
    "# Get a list of target files, excluding \"satirical\" labels.\n",
    "\n",
    "files = get_file_list('../../news-crawler/data/articles/', exclude_regex='.*satirical')\n",
    "print('Number of conservative/liberal articles: {}'.format(len(files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Break up the file list into cpu_count chunks.\n",
    "\n",
    "files = [ map(str, x) for x in np.array_split(files, mp.cpu_count())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 342 ms, sys: 191 ms, total: 533 ms\n",
      "Wall time: 24.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Use multiprocessing to read the files into a dataframe.  We'll filter out\n",
    "# those articles not labeled with taxonomy \"politics\".\n",
    "\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "df = pool.map(create_dataframe_mp, files)\n",
    "\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape: (24115, 3)\n"
     ]
    }
   ],
   "source": [
    "# Concatenate multiprocessing results into a single dataframe.\n",
    "\n",
    "df = pd.concat(df, axis=0, ignore_index=True)\n",
    "print('Dataframe shape: {}'.format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract top-level domain for later...\n",
    "\n",
    "df['domain'] = df['url'].map(tld.get_tld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>url</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Big government has been crushing the United St...</td>\n",
       "      <td>conservative</td>\n",
       "      <td>http://dailysurge.com/2016/12/commentary-resto...</td>\n",
       "      <td>dailysurge.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>During the eight years of the Obama administra...</td>\n",
       "      <td>conservative</td>\n",
       "      <td>http://dailysurge.com/2016/12/commentary-welco...</td>\n",
       "      <td>dailysurge.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We are witnessing the rise of a new right whic...</td>\n",
       "      <td>conservative</td>\n",
       "      <td>http://dailysurge.com/2016/11/commentary-28th-...</td>\n",
       "      <td>dailysurge.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If theres one thing that Americans find intole...</td>\n",
       "      <td>conservative</td>\n",
       "      <td>http://dailysurge.com/2016/11/commentary-retur...</td>\n",
       "      <td>dailysurge.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is Airbnb? Airbnb is an online marketplac...</td>\n",
       "      <td>conservative</td>\n",
       "      <td>http://dailysurge.com/2016/11/commentary-airbn...</td>\n",
       "      <td>dailysurge.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text         label  \\\n",
       "0  Big government has been crushing the United St...  conservative   \n",
       "1  During the eight years of the Obama administra...  conservative   \n",
       "2  We are witnessing the rise of a new right whic...  conservative   \n",
       "3  If theres one thing that Americans find intole...  conservative   \n",
       "4  What is Airbnb? Airbnb is an online marketplac...  conservative   \n",
       "\n",
       "                                                 url          domain  \n",
       "0  http://dailysurge.com/2016/12/commentary-resto...  dailysurge.com  \n",
       "1  http://dailysurge.com/2016/12/commentary-welco...  dailysurge.com  \n",
       "2  http://dailysurge.com/2016/11/commentary-28th-...  dailysurge.com  \n",
       "3  http://dailysurge.com/2016/11/commentary-retur...  dailysurge.com  \n",
       "4  http://dailysurge.com/2016/11/commentary-airbn...  dailysurge.com  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the data using `spacy` NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load spacy's NLP model for English.\n",
    "NLP = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We'll keep article if it has at least min_sents sentences.\n",
    "min_sents = 3     \n",
    "\n",
    "# Whether to exclude stopwords.\n",
    "exclude_stops = False\n",
    "\n",
    "# In dumb mode we don't lemmatize or otherwise filter the sequences.\n",
    "dumb = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function to parse a document.\n",
    "\n",
    "def parse_doc(doc, exclude_stops=False, min_sents=3, dump=False):\n",
    "  '''Return text containing only lemmatized, alphanumeric tokens with POS tag.\n",
    "\n",
    "  Args:\n",
    "    doc: spacy parsed doc\n",
    "    min_sents:  minimum number of sentences to parse, else return ''\n",
    "\n",
    "  Returns parsed string with appended PoS tags.\n",
    "  '''\n",
    "  \n",
    "  def token_formatter(token):\n",
    "    return '{}_{}'.format(x.lemma_, x.pos_)\n",
    "  \n",
    "  # Parse the doc.\n",
    "  doc = NLP(doc)\n",
    "  \n",
    "  # Check that document has at least min_sents sentences.\n",
    "  num_sents = len([sent for sent in doc.sents])\n",
    "  if num_sents < min_sents:\n",
    "    return ''\n",
    "  \n",
    "  # Keep alphanumeric, lemmatized tokens with PoS tags.\n",
    "  if dumb:\n",
    "    text = [str(x).lower() for x in doc]\n",
    "  elif exclude_stops:\n",
    "    text = [token_formatter(x) for x in doc if x.is_alpha and not x.is_stop]\n",
    "  else:\n",
    "    text = [token_formatter(x) for x in doc if x.is_alpha]\n",
    "    \n",
    "  return ' '.join(text)\n",
    "\n",
    "def parse_doc_mp(args):\n",
    "  '''Helper function for multiprocessing.'''\n",
    "  return parse_doc(args[0], args[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the arg list for multiprocessing.\n",
    "\n",
    "args = zip(df['text'].tolist(), [exclude_stops]*df.shape[0], [min_sents]*df.shape[0],\n",
    "           [dumb]*df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 474 ms, sys: 284 ms, total: 758 ms\n",
      "Wall time: 3min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Parse the documents using multiprocessing pool.  In my experiments this was 5x\n",
    "# faster than using NLP.pipe (?).\n",
    "\n",
    "pool = mp.Pool()\n",
    "\n",
    "df['tokenized_text'] = pool.map(parse_doc_mp, args)\n",
    "\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>url</th>\n",
       "      <th>domain</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Big government has been crushing the United St...</td>\n",
       "      <td>conservative</td>\n",
       "      <td>http://dailysurge.com/2016/12/commentary-resto...</td>\n",
       "      <td>dailysurge.com</td>\n",
       "      <td>big government has been crushing the united st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>During the eight years of the Obama administra...</td>\n",
       "      <td>conservative</td>\n",
       "      <td>http://dailysurge.com/2016/12/commentary-welco...</td>\n",
       "      <td>dailysurge.com</td>\n",
       "      <td>during the eight years of the obama administra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We are witnessing the rise of a new right whic...</td>\n",
       "      <td>conservative</td>\n",
       "      <td>http://dailysurge.com/2016/11/commentary-28th-...</td>\n",
       "      <td>dailysurge.com</td>\n",
       "      <td>we are witnessing the rise of a new right whic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If theres one thing that Americans find intole...</td>\n",
       "      <td>conservative</td>\n",
       "      <td>http://dailysurge.com/2016/11/commentary-retur...</td>\n",
       "      <td>dailysurge.com</td>\n",
       "      <td>if there s one thing that americans find intol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is Airbnb? Airbnb is an online marketplac...</td>\n",
       "      <td>conservative</td>\n",
       "      <td>http://dailysurge.com/2016/11/commentary-airbn...</td>\n",
       "      <td>dailysurge.com</td>\n",
       "      <td>what is airbnb ? airbnb is an online marketpla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text         label  \\\n",
       "0  Big government has been crushing the United St...  conservative   \n",
       "1  During the eight years of the Obama administra...  conservative   \n",
       "2  We are witnessing the rise of a new right whic...  conservative   \n",
       "3  If theres one thing that Americans find intole...  conservative   \n",
       "4  What is Airbnb? Airbnb is an online marketplac...  conservative   \n",
       "\n",
       "                                                 url          domain  \\\n",
       "0  http://dailysurge.com/2016/12/commentary-resto...  dailysurge.com   \n",
       "1  http://dailysurge.com/2016/12/commentary-welco...  dailysurge.com   \n",
       "2  http://dailysurge.com/2016/11/commentary-28th-...  dailysurge.com   \n",
       "3  http://dailysurge.com/2016/11/commentary-retur...  dailysurge.com   \n",
       "4  http://dailysurge.com/2016/11/commentary-airbn...  dailysurge.com   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  big government has been crushing the united st...  \n",
       "1  during the eight years of the obama administra...  \n",
       "2  we are witnessing the rise of a new right whic...  \n",
       "3  if there s one thing that americans find intol...  \n",
       "4  what is airbnb ? airbnb is an online marketpla...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23452, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows where the text was too short and we got a '' from the parse.\n",
    "\n",
    "df = df.drop(df.index[np.where(df['tokenized_text'] == '')[0]])\n",
    "df.index = range(df.shape[0])  # Need to re-index again.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary size: 132979\n",
      "CPU times: user 8.02 s, sys: 28.2 ms, total: 8.04 s\n",
      "Wall time: 8.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Build a dictionary with word counts.\n",
    "\n",
    "c = Counter()\n",
    "for row in df.iterrows():\n",
    "  c.update(row[1]['tokenized_text'].split())\n",
    "  \n",
    "print('Dictionary size: {}'.format(len(c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 vocab words:\n",
      "[('the', 878245), (',', 786639), ('.', 662752), ('to', 423195), ('of', 380543), ('and', 355242), ('a', 330111), ('in', 292296), ('that', 212405), ('\"', 156619)]\n"
     ]
    }
   ],
   "source": [
    "# Create a list object from the counter and sort by count.\n",
    "\n",
    "vocab_list = [(k, v) for k,v in c.iteritems()]\n",
    "vocab_list.sort(key=lambda x: -1 * x[1])\n",
    "\n",
    "print('Top 10 vocab words:')\n",
    "print(vocab_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create word:index and index:word dicts for encoding/decoding.\n",
    "\n",
    "vocab_word2idx = {x[0]: ix for ix,x in enumerate(vocab_list)}\n",
    "vocab_idx2word = {v: k for k,v in vocab_word2idx.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.04 s, sys: 60.1 ms, total: 3.1 s\n",
      "Wall time: 3.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Encode the corpus.\n",
    "\n",
    "df['encoded_text'] = df['tokenized_text'].map(lambda x: [vocab_word2idx[y] for y in x.split()])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>url</th>\n",
       "      <th>domain</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>encoded_text</th>\n",
       "      <th>encoded_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Big government has been crushing the United St...</td>\n",
       "      <td>conservative</td>\n",
       "      <td>http://dailysurge.com/2016/12/commentary-resto...</td>\n",
       "      <td>dailysurge.com</td>\n",
       "      <td>big government has been crushing the united st...</td>\n",
       "      <td>[384, 100, 31, 49, 9784, 0, 101, 80, 10, 0, 34...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>During the eight years of the Obama administra...</td>\n",
       "      <td>conservative</td>\n",
       "      <td>http://dailysurge.com/2016/12/commentary-welco...</td>\n",
       "      <td>dailysurge.com</td>\n",
       "      <td>during the eight years of the obama administra...</td>\n",
       "      <td>[112, 0, 703, 102, 4, 0, 72, 99, 1, 39, 5270, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We are witnessing the rise of a new right whic...</td>\n",
       "      <td>conservative</td>\n",
       "      <td>http://dailysurge.com/2016/11/commentary-28th-...</td>\n",
       "      <td>dailysurge.com</td>\n",
       "      <td>we are witnessing the rise of a new right whic...</td>\n",
       "      <td>[39, 30, 9394, 0, 1429, 4, 6, 57, 164, 60, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If theres one thing that Americans find intole...</td>\n",
       "      <td>conservative</td>\n",
       "      <td>http://dailysurge.com/2016/11/commentary-retur...</td>\n",
       "      <td>dailysurge.com</td>\n",
       "      <td>if there s one thing that americans find intol...</td>\n",
       "      <td>[63, 56, 150, 51, 478, 8, 230, 482, 10147, 174...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is Airbnb? Airbnb is an online marketplac...</td>\n",
       "      <td>conservative</td>\n",
       "      <td>http://dailysurge.com/2016/11/commentary-airbn...</td>\n",
       "      <td>dailysurge.com</td>\n",
       "      <td>what is airbnb ? airbnb is an online marketpla...</td>\n",
       "      <td>[55, 13, 7459, 91, 7459, 13, 36, 780, 6163, 8,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text         label  \\\n",
       "0  Big government has been crushing the United St...  conservative   \n",
       "1  During the eight years of the Obama administra...  conservative   \n",
       "2  We are witnessing the rise of a new right whic...  conservative   \n",
       "3  If theres one thing that Americans find intole...  conservative   \n",
       "4  What is Airbnb? Airbnb is an online marketplac...  conservative   \n",
       "\n",
       "                                                 url          domain  \\\n",
       "0  http://dailysurge.com/2016/12/commentary-resto...  dailysurge.com   \n",
       "1  http://dailysurge.com/2016/12/commentary-welco...  dailysurge.com   \n",
       "2  http://dailysurge.com/2016/11/commentary-28th-...  dailysurge.com   \n",
       "3  http://dailysurge.com/2016/11/commentary-retur...  dailysurge.com   \n",
       "4  http://dailysurge.com/2016/11/commentary-airbn...  dailysurge.com   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  big government has been crushing the united st...   \n",
       "1  during the eight years of the obama administra...   \n",
       "2  we are witnessing the rise of a new right whic...   \n",
       "3  if there s one thing that americans find intol...   \n",
       "4  what is airbnb ? airbnb is an online marketpla...   \n",
       "\n",
       "                                        encoded_text  encoded_label  \n",
       "0  [384, 100, 31, 49, 9784, 0, 101, 80, 10, 0, 34...              0  \n",
       "1  [112, 0, 703, 102, 4, 0, 72, 99, 1, 39, 5270, ...              0  \n",
       "2  [39, 30, 9394, 0, 1429, 4, 6, 57, 164, 60, 1, ...              0  \n",
       "3  [63, 56, 150, 51, 478, 8, 230, 482, 10147, 174...              0  \n",
       "4  [55, 13, 7459, 91, 7459, 13, 36, 780, 6163, 8,...              0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the labels.\n",
    "\n",
    "df['encoded_label'] = LabelEncoder().fit_transform([x for x in df['label']])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag = 'dumb'\n",
    "\n",
    "# Save the dataframe.\n",
    "df.to_pickle('final-dataframe-{}.pkl'.format(tag))\n",
    "\n",
    "# Save the vocabulary dictionaries.\n",
    "to_pkl = {\n",
    "  'word2idx': vocab_word2idx,\n",
    "  'idx2word': vocab_idx2word,\n",
    "  'ranked_list': vocab_list\n",
    "}\n",
    "\n",
    "with open('final-vocab-{}.pkl'.format(tag), 'w') as f:\n",
    "  pickle.dump(to_pkl, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text              What is Airbnb? Airbnb is an online marketplac...\n",
       "label                                                  conservative\n",
       "url               http://dailysurge.com/2016/11/commentary-airbn...\n",
       "domain                                               dailysurge.com\n",
       "tokenized_text    airbnb_PROPN airbnb_PROPN online_ADJ marketpla...\n",
       "encoded_text      [6401, 6401, 1974, 4446, 165, 2, 144, 1031, 13...\n",
       "encoded_label                                                     0\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[4, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
